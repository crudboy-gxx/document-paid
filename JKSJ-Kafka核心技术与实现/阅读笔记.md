# 入门知识 
+ kafka的记录、主题、分区、消息位移、副本、消费者位移、消费组、重平衡的基本概念，数据持久化和删除机制。
  + 只有主副本才可以对外服务。
  + kafka持久化通过消息日志来保存数据，日志是一个只能追加写的物理文件。在底层，日志又被切分成多个日志段，写满一个日志段后，kafka会切分出一个新的日志段，并将老的封存起来。后台有定时任务检查老的日志段是否可以删除，来回收磁盘空间。
+ kafka是消息引擎系统，也是一个分布式流处理平台。

# 集群部署方案
+ kafka磁盘容量规划计算方式
  + 计算方式与每条消息大小、每天的消息数、消息存储时间、备份数、是否启用压缩有关。
  + 计算下每天1一亿条1KB大小的消息，保留2分且留存2周时间。一天的总空间为1亿 * 1KB * 2/1024/1024=200GB，另外考虑索引等其他数据，预留10%空间总容量为220GB，保存两周220GB * 14=3TB，kafka支持数据压缩，假设压缩比0.75，最后规划的空间是3 * 0.75=2.25TB
+ kafka带宽规划计算方式
  + 假设机房环境是千兆网络1Gbps，业务目标是1小时内处理1TB的数据，kafka需要多少台服务器。每台机器除去其他资源，保留70%的带宽资源，也就是单台服务器最大带宽资源为700MB。通常在额外预留出2/3，即单台服务器可用带宽为700Mb/3=240Mbps。根据业务目标1TB * 1024 * 1024/3600s=290MB，转换为带宽290MB * 8=2330Mb，需要的机器数为2330/240约为10台服务器。如果需要额外复制需要在倍增。

# 集群参数
+ broker端参数：
  + 存储位置：log.dirs
  + zk：zookeeper.connect
  + broker连接：listeners、advertised.listeners
  + topic管理：auto.create.topics.enable、unclean.leader.election.enable、auto.leader.rebalance.enable
  + 数据留存：log.retention.{hours|minutes|ms}、log.retention.bytes、message.max.bytes
+ topic级别参数：
  + retention.ms、retention.bytes、max.message.bytes
+ JVM参数
  + 堆大小设为6GB；KAFKA_HEAP_OPTS、KAFKA_JVM_PERFORMANCE_OPTS
+ 操作系统参数
  + limit -n设为100w、swap不要设为1、Flash落盘时间设置大些

# 分区
+ 分区策略：Round-robin轮询、Randomness随机、key-orderging消息键（自定义）  
+ 如何保障有前后关系消息的顺序消费？
  + 一种不太好的方案就是只创建一个分区，这样消息就只能在一个分区读写，因此保证了全局的顺序性。第二种方案是根据选一个字段，保证前后存在关系的消息发送到同一个分区内，保证分区内的消息顺序。
+ 消费程序可以只消费topic中某个分区的消息。

# 压缩
+ kafka的消息层面分为两层，消息集合和消息。一个消息集合有若干条日志项，日志项才是封装消息的地方。
+ 压缩可以发生在两个地方：生产者端和Broker端。大多数情况broker获取消息后原封不动保存了，只有两个例外：
  + 1）生产者端和broker端如果制定不通的压缩方式，会导致broker解压缩和再压缩，通常表现CPU使用率飙升。
  + 2）新版本消息执行向老版本格式转换，这个过程会涉及消息的解压缩和重新压缩，并且还会丧失零拷贝的特性。
+ 因为broker存在对消息的验证，所以生产者压缩传输后，broker必须解压缩。这样减少网络传输导致处理消息慢的情况，是否有更好的方式？目前官方已经修复。

# 丢数据
+ 生产者丢数据：如果调用producer.send(msg)这个API，他是异步发送消息，立即返回，我们并不知道是否发送成功了。可能是网络抖动导致broker没有接收到，也可能是消息不合格被broker拒收。
  + 解决方法：要使用带有会通知的api，producer.send(msg,callback)，不要使用producer.send(msg)。
+ 消费者丢数据：消费端没有遵从先消费成功，之后在位移的方式，而是设置自动提交，取数据后位移。
  + 解决方法：消费端不要开启自动提交位移。
+ 最佳实践
  + 1.生产者不要使用producer.send(msg)，而要使用 producer.send(msg, callback)。
  + 2.生产者设置acks=all，表明所有副本broker都接收到消息才算已提交。
  + 3.生产者设置retrues为较大的值，他大于0能够自动重试消息发送，避免消息丢失。
  + 4.broker端设置unclean.leader.election.enable=false，设置不去精选分区leader。
  + 5.broker端设置replication.factor >= 3，保存消息份数。
  + 6.broker端设置min.insync.replicas > 1，消息至少写入多个副本才算已提交。
  + 7.broker端确保replication.factor > min.insync.replicas，推荐replication.factor = min.insync.replicas + 1，
  + 8.消费端enable.auto.commit=false，采用手动提交位移方式。

# 